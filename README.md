
# üåü CIS221 Course- My Analytics Application Experience

> A reflection on my journey with EDA, Inferential Regression, and Machine Learning Regression, using the CRISP-DM framework and a business-focused mindset.

---

## üìö Table of Contents

- [3.1 Challenges I Experienced](#31-challenges-i-experienced-in-eda-inferential-regression-analysis-and-regression-for-machine-learning)
- [3.2 Why These Challenges Happened & What I Learned](#32-why-did-these-challenges-happen--what-did-i-learn)
- [3.3 What I Need to Do Better Next Time](#33-what-i-need-to-do-better-next-time)

---

## 3.1. Challenges I Experienced in EDA, Inferential Regression Analysis, and Regression for Machine Learning

Throughout the midterm tasks, I faced several challenges while working on **Exploratory Data Analysis (EDA)**, **Inferential Regression**, and **Machine Learning Regression**.

### üîç Exploratory Data Analysis (EDA)

During EDA, I struggled with fully understanding the dataset because of several issues:

- Handling **missing values**, **inconsistent formatting**, and **outliers**, which affected the accuracy of my insights.
- Difficulty interpreting visualizations when **multiple variables interacted** with each other.
- Uncertainty about which plots were most appropriate for showing relationships and trends.

These made it harder for me to clearly see the story behind the data.

### üìâ Inferential Regression Analysis

In Inferential Regression, I encountered more conceptual challenges:

- Understanding **regression coefficients**, **p-values**, and **confidence intervals** was not straightforward at first.
- I found it difficult to remember and check the **assumptions of regression**, such as linearity, normality, and homoscedasticity.
- Translating the statistical outputs into **meaningful, real-world conclusions** was especially challenging.

I realized that knowing how to run a regression is different from being able to clearly explain what the results actually mean.

### ü§ñ Regression for Machine Learning

When I moved to Machine Learning Regression, the challenges became more technical:

- Difficulty in **selecting appropriate features** and preparing the data correctly (encoding, scaling, splitting).
- Struggles with **interpreting performance metrics** like MAE, RMSE, and R¬≤.
- Concerns about **overfitting** and understanding why one model performed better than another.
- Confusion about how to connect the model results back to the **business problem** or real-life decision-making.

All of these made the machine learning part feel both interesting and overwhelming at the same time.

---

## 3.2. Why Did These Challenges Happen? What Did I Learn?

These challenges happened mainly because many of the concepts, tools, and techniques were still **new to me**.

### üß† Reasons Behind the Challenges

- **Real-world data is rarely clean**, so encountering missing values, noise, and outliers made the analysis more complicated than I initially expected.
- I was still learning how to use multiple tools simultaneously, such as **Jupyter Notebook**, **pandas**, **scikit-learn**, and various **visualization libraries**.
- There was a clear **gap between theory and practice**‚Äîunderstanding a concept in class is very different from applying it to an actual dataset.
- I also realized that interpreting results from a **business perspective** requires a different mindset than simply producing numbers and graphs.

All of this contributed to why some steps felt slower, more confusing, or more difficult.

### üéì Lessons That Will Help Me Improve

From these experiences, I learned several important things that will guide how I work in the future:

- The importance of **thorough data cleaning** before moving to analysis or modeling.
- The need to **check statistical assumptions** to ensure that my interpretations are valid.
- The value of **documenting each step clearly** in my notebook so that the process is transparent and reproducible.
- The importance of always connecting **technical findings to real-world implications**, especially from a **business and decision-making perspective**.
- Following a structured approach like **CRISP-DM** (Business Understanding ‚Üí Data Understanding ‚Üí Data Preparation ‚Üí Modeling ‚Üí Evaluation ‚Üí Deployment) makes the process clearer and more logical.

These lessons are already helping me approach analytics tasks more carefully and confidently.

---

## 3.3. What I Need to Do Better Next Time

Next time, I want to apply what I‚Äôve learned so I can work more efficiently and produce more meaningful insights.

### üìà Areas I Want to Improve

- **Spend more time on data quality** before modeling:
  - Check for missing values, duplicates, and inconsistencies.
  - Identify and handle outliers early in the process.
- **Practice interpreting correlations and regression outputs** in simpler, more intuitive terms:
  - Explain whether relationships are strong/weak, positive/negative.
  - Describe what happens to the target variable when a predictor changes.
- **Follow the CRISP-DM framework more consistently**:
  - Start with clear **Business Understanding** so that every step is aligned with the problem.
  - Make sure that **Evaluation** includes both technical performance and business interpretation.
- **Strengthen my understanding of model assumptions and metrics**:
  - Learn when to use certain models and how to evaluate them properly.
  - Be more comfortable explaining MAE, RMSE, R¬≤, and other metrics.
- **Improve how I communicate insights**:
  - Focus more on the **business implications** of the results.
  - Answer questions like ‚ÄúSo what?‚Äù and ‚ÄúWhat should we do next?‚Äù in my conclusions.

By applying these improvements, I believe I can produce more accurate analyses and more **professional, insightful work** that is aligned with the expectations for **analytics and business analyst roles**.

---
